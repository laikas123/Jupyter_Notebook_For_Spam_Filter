{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with windows-1250 , trying different encoding\n",
      "got unicode error with windows-1252 , trying different encoding\n",
      "got unicode error with ascii , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with windows-1250 , trying different encoding\n",
      "got unicode error with windows-1252 , trying different encoding\n",
      "got unicode error with ascii , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with windows-1250 , trying different encoding\n",
      "got unicode error with windows-1252 , trying different encoding\n",
      "got unicode error with ascii , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with windows-1250 , trying different encoding\n",
      "got unicode error with windows-1252 , trying different encoding\n",
      "got unicode error with ascii , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with windows-1250 , trying different encoding\n",
      "got unicode error with windows-1252 , trying different encoding\n",
      "got unicode error with ascii , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with windows-1250 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "got unicode error with utf-8 , trying different encoding\n",
      "DONE READING ALL EMAIL FILES Email counts Spam:  496  Ham:  2551\n",
      "DONE READING ALL DICTIONARY FILES Length Normal Dict:  466599  Length Spam Dict:  60043\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "#SPAM PATH HAM PATH NORM DICT PATH SPAM DICT PATH GLOBAL VARIABLES \n",
    "SPAM_PATH = os.path.join(\"HamandSpam\", \"Spam\", \"spam\") \n",
    "\n",
    "HAM_PATH = os.path.join(\"HamandSpam\", \"Ham\", \"easy_ham\") \n",
    "\n",
    "NORMAL_DICTIONARY_PATH = os.path.join(\"Dictionaries\", \"dictionary.txt\") \n",
    "\n",
    "SPAM_DICTIONARY_PATH = os.path.join(\"Dictionaries\", \"spamdictionary.txt\") \n",
    "\n",
    "#HYPERPARAMETERS \n",
    "REMOVE_PUNCTUATION = True\n",
    "REMOVE_SYMBOLS = True\n",
    "# if False count how many times a word shows up per word\n",
    "# if True count words only once, whether they appear or don't\n",
    "COUNT_SINGLE_INSTANCE = False\n",
    "SET_ALL_WORDS_UPPER_CASE = True\n",
    "COUNT_INVALID_LONE_LETTERS = True\n",
    "CHECK_IF_EMAIL_CONTAINS_MARKUP = True\n",
    "COUNT_UPPER_CASE_WORDS_BEFORE_PROCESSING = True\n",
    "COUNT_ALL_SYMBOL_WORDS_LENGTH_THRESHOLD = [True, 2]\n",
    "#some emails have rather long words, especially spam\n",
    "#this leads to a large dataset when looking at unique words\n",
    "#setting shortest and longest word limits help reduce dataset size\n",
    "REMOVE_WORDS_LENGTH_THRESHOLD = [True, 4, 8]\n",
    "CHECK_MARKUP_TEXT_PRESENCE = True\n",
    "\n",
    "#HELPER FUNCTIONS \n",
    "def removeAllSymbolsFromAString(word):\n",
    "    for letter in word:\n",
    "        if(isSymbol(letter)):\n",
    "            word = word.replace(letter, \"\")\n",
    "\n",
    "    return word\n",
    "\n",
    "\n",
    "def removeAllPunctFromAString(word):\n",
    "    for letter in word:\n",
    "        if(isPunctuation(letter)):\n",
    "            word = word.replace(letter, \"\")\n",
    "\n",
    "    return word\n",
    "    \n",
    "\n",
    "def isPunctuation(letter):\n",
    "    punctuation_text = re.search(r\"([/./?\\,\\'\\-\\—\\!\\:\\;\\[\\]\\(\\)\\/\\\\\\\"])\", letter)\n",
    "    if(punctuation_text is None):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "# checker function for making sure invalid lone letter count only\n",
    "# increments for actual letters\n",
    "def isLetter(letter):\n",
    "    letter_text = re.search(r\"([A-Za-z])\", letter)\n",
    "    if(letter_text is None):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# capital letter checker, same as above function but don't capitalize\n",
    "# input prior to checking\n",
    "def isCapitalLetter(letter):\n",
    "    letter_text = re.search(r\"([A-Z])\", letter)\n",
    "    if(letter_text is None):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def isUpperCaseWord(word):\n",
    "    # remove symbols and punctuation since only letters can be capital\n",
    "    word = removeAllPunctFromAString(word)\n",
    "    word = removeAllSymbolsFromAString(word)\n",
    "    # if the word was just symbols and punctuation\n",
    "    # return False if the word was all symbols and punctuation\n",
    "    if(len(word) == 0):\n",
    "        return False\n",
    "    sawACapitalLetter = False\n",
    "    for letter in word:\n",
    "        if(isCapitalLetter(letter) == False):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def isSymbol(letter):\n",
    "    symbol_text = re.search(r\"([\\?\\/\\\\\\|\\~\\`\\<\\>\\,\\.\\:\\;\\\\\\'\\{\\}\\-\\—\\=\\+\\!\\@\\#\\\\\\$\\%\\^\\&\\*])\", letter)\n",
    "    if(symbol_text is None):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def isAllSymbolWord(word):\n",
    "    for letter in word:\n",
    "        if(letter == \" \" or letter == \"\"):\n",
    "            return False\n",
    "        if(isSymbol(letter) != True):\n",
    "            return False\n",
    "    return True\n",
    "def isMarkupWord(word):\n",
    "    markup_text = re.search(r\"\\<([A-Za-z0-9_]+)\\>\", word)\n",
    "    if(markup_text is None):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "#keys used in the containers for data that shouldn't be overwritten if an email contains them\n",
    "def isSpecialWord(word):\n",
    "    if(word == \"upperCnt\" or word == \"symbolCnt\" or word == \"loneCnt\" or word = \"markupPrsnt\" or word = \"IsSpam\"):\n",
    "        print(\"Special Word was present\")\n",
    "        sys.Exit()\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def GetDataApplyHyperparameters(spam_path = SPAM_PATH, ham_path = HAM_PATH, norm_dict_path = NORMAL_DICTIONARY_PATH,\n",
    "                               spam_dict_path = SPAM_DICTIONARY_PATH, remove_punctuation = REMOVE_PUNCTUATION,\n",
    "                        remove_symbols = REMOVE_SYMBOLS, count_single_instance = COUNT_SINGLE_INSTANCE,\n",
    "                        set_all_words_upper_case = SET_ALL_WORDS_UPPER_CASE, \n",
    "                         count_invalid_lone_letters = COUNT_INVALID_LONE_LETTERS, \n",
    "                        count_upper_case_words_before_processing = COUNT_UPPER_CASE_WORDS_BEFORE_PROCESSING,\n",
    "                        count_all_symbol_words_length_threshold = COUNT_ALL_SYMBOL_WORDS_LENGTH_THRESHOLD,\n",
    "                        remove_words_length_threshold = REMOVE_WORDS_LENGTH_THRESHOLD, \n",
    "                                check_markup_text_presence = CHECK_MARKUP_TEXT_PRESENCE):\n",
    "    \n",
    "    \n",
    "    onlyfiles = [f for f in listdir(spam_path) if isfile(os.path.join(spam_path, f))]\n",
    "\n",
    "    spam_word_count_per_email_data = {}\n",
    "\n",
    "    email_counter = 1\n",
    "\n",
    "\n",
    "    for filename in onlyfiles:\n",
    "\n",
    "        dictionaryName = \"Email\" + str(email_counter)\n",
    "\n",
    "        spam_word_count_per_email_data[dictionaryName] = {}\n",
    "\n",
    "        encodings = ['utf-8', 'windows-1250', 'windows-1252', 'ascii']\n",
    "        for en in encodings:\n",
    "            try:\n",
    "\n",
    "                file1 = open(os.path.join(spam_path, filename), 'r', encoding=en)\n",
    "\n",
    "                alllines = file1.read()\n",
    "                alllinessplit = alllines.split()\n",
    "\n",
    "                invalidLoneLetterCount = 0\n",
    "                preProccessUpperCaseCount = 0\n",
    "                allSymbolWordsCount = 0\n",
    "\n",
    "                sawMarkupWord = False\n",
    "\n",
    "                for word in alllinessplit:\n",
    "                    if(isinstance(word, str)):\n",
    "\n",
    "                        if(isSpecialWord(word)):\n",
    "                            continue\n",
    "                        \n",
    "                        if(word == \" \" or word == \"\"):\n",
    "                            continue\n",
    "\n",
    "                        #markup check should be done before all processing\n",
    "                        if(check_markup_text_presence):\n",
    "                            if(isMarkupWord(word)):\n",
    "                                sawMarkupWord = True\n",
    "                                continue\n",
    "                                \n",
    "                            \n",
    "                        # counts that need to be done pre proccessing\n",
    "                        if(count_upper_case_words_before_processing):\n",
    "                            if(isUpperCaseWord(word)):\n",
    "                                preProccessUpperCaseCount = preProccessUpperCaseCount + 1\n",
    "                        if(count_all_symbol_words_length_threshold[0]):\n",
    "                            if(len(word) >= count_all_symbol_words_length_threshold[1]):\n",
    "                                if(isAllSymbolWord(word)):\n",
    "                                    allSymbolWordsCount = allSymbolWordsCount + 1\n",
    "                                    continue\n",
    "                                    \n",
    "\n",
    "                        # hyper parameter filters\n",
    "                        wordAfterHyperParameters = word\n",
    "                        if remove_punctuation:\n",
    "                            wordAfterHyperParameters = removeAllPunctFromAString(\n",
    "                                wordAfterHyperParameters)\n",
    "                        if remove_symbols:\n",
    "                            wordAfterHyperParameters = removeAllSymbolsFromAString(\n",
    "                                wordAfterHyperParameters)\n",
    "                        if set_all_words_upper_case:\n",
    "                            wordAfterHyperParameters = wordAfterHyperParameters.upper()\n",
    "\n",
    "                        # count to do after processing\n",
    "                        if len(wordAfterHyperParameters) == 1 and isLetter(\n",
    "                                wordAfterHyperParameters):\n",
    "\n",
    "                            if(count_invalid_lone_letters):\n",
    "                                if(wordAfterHyperParameters != \"i\" and wordAfterHyperParameters != \"I\" and wordAfterHyperParameters != \"a\" and wordAfterHyperParameters != \"A\"):\n",
    "                                    invalidLoneLetterCount = invalidLoneLetterCount + 1\n",
    "\n",
    "                        # count occurrences only for the hyperparameter being set\n",
    "                        if wordAfterHyperParameters in spam_word_count_per_email_data[\n",
    "                                dictionaryName] and count_single_instance == False:\n",
    "                            spam_word_count_per_email_data[dictionaryName][wordAfterHyperParameters] = spam_word_count_per_email_data[\n",
    "                                dictionaryName][wordAfterHyperParameters] + 1\n",
    "                        elif (len(wordAfterHyperParameters) > remove_words_length_threshold[1] and \n",
    "                             len(wordAfterHyperParameters) < remove_words_length_threshold[2]):\n",
    "                            spam_word_count_per_email_data[dictionaryName][wordAfterHyperParameters] = 1\n",
    "                email_counter = email_counter + 1\n",
    "                #if hyperparameters were enabled add their respective values to the container\n",
    "                if(count_invalid_lone_letters):\n",
    "                    spam_word_count_per_email_data[dictionaryName][\"loneCnt\"] = invalidLoneLetterCount\n",
    "                if(count_upper_case_words_before_processing):\n",
    "                    spam_word_count_per_email_data[dictionaryName][\"upperCnt\"] = preProccessUpperCaseCount\n",
    "                if(count_all_symbol_words_length_threshold):\n",
    "                    spam_word_count_per_email_data[dictionaryName][\"symbolCnt\"] = allSymbolWordsCount\n",
    "                if(check_markup_text_presence):\n",
    "                    if(sawMarkupWord):\n",
    "                        spam_word_count_per_email_data[dictionaryName][\"markupPrsnt\"] = 1\n",
    "                    else:\n",
    "                        spam_word_count_per_email_data[dictionaryName][\"markupPrsnt\"] = 0\n",
    "                file1.close()\n",
    "            except UnicodeDecodeError:\n",
    "                print('got unicode error with %s , trying different encoding' % en)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    onlyfiles = [f for f in listdir(ham_path) if isfile(os.path.join(ham_path, f))]\n",
    "\n",
    "\n",
    "    ham_word_count_per_email_data = {}\n",
    "\n",
    "    email_counter = 1\n",
    "\n",
    "    for filename in onlyfiles:\n",
    "\n",
    "        dictionaryName = \"Email\" + str(email_counter)\n",
    "\n",
    "        ham_word_count_per_email_data[dictionaryName] = {}\n",
    "\n",
    "        encodings = ['utf-8', 'windows-1250', 'windows-1252', 'ascii']\n",
    "        for en in encodings:\n",
    "            try:\n",
    "\n",
    "                file1 = open(os.path.join(ham_path, filename), 'r', encoding=en)\n",
    "\n",
    "                alllines = file1.read()\n",
    "                alllinessplit = alllines.split()\n",
    "\n",
    "                invalidLoneLetterCount = 0\n",
    "                preProccessUpperCaseCount = 0\n",
    "                allSymbolWordsCount = 0\n",
    "                \n",
    "                sawMarkupWord = False\n",
    "                \n",
    "                for word in alllinessplit:\n",
    "                    if(isinstance(word, str)):\n",
    "                        \n",
    "                        if(isSpecialWord(word)):\n",
    "                            continue\n",
    "\n",
    "                        if(word == \" \" or word == \"\"):\n",
    "                            continue\n",
    "                            \n",
    "                        #markup check should be done before all processing\n",
    "                        if(check_markup_text_presence):\n",
    "                            if(isMarkupWord(word)):\n",
    "                                sawMarkupWord = True\n",
    "                                continue\n",
    "                                    \n",
    "                        # counts that need to be done pre proccessing\n",
    "                        if(count_upper_case_words_before_processing):\n",
    "                            if(isUpperCaseWord(word)):\n",
    "                                preProccessUpperCaseCount = preProccessUpperCaseCount + 1\n",
    "                        if(count_all_symbol_words_length_threshold[0]):\n",
    "                            if(len(word) > count_all_symbol_words_length_threshold[1]):\n",
    "                                if(isAllSymbolWord(word)):\n",
    "                                    allSymbolWordsCount = allSymbolWordsCount + 1\n",
    "                                    continue\n",
    "                                    \n",
    "\n",
    "                        # hyper parameter filters\n",
    "                        wordAfterHyperParameters = word\n",
    "                        if remove_punctuation:\n",
    "                            wordAfterHyperParameters = removeAllPunctFromAString(\n",
    "                                wordAfterHyperParameters)\n",
    "                        if remove_symbols:\n",
    "                            wordAfterHyperParameters = removeAllSymbolsFromAString(\n",
    "                                wordAfterHyperParameters)\n",
    "                        if set_all_words_upper_case:\n",
    "                            wordAfterHyperParameters = wordAfterHyperParameters.upper()\n",
    "\n",
    "                        # count to do after processing\n",
    "                        if len(wordAfterHyperParameters) == 1 and isLetter(\n",
    "                                wordAfterHyperParameters):\n",
    "\n",
    "                            if(count_invalid_lone_letters):\n",
    "                                if(wordAfterHyperParameters != \"i\" and wordAfterHyperParameters != \"I\" and wordAfterHyperParameters != \"a\" and wordAfterHyperParameters != \"A\"):\n",
    "                                    invalidLoneLetterCount = invalidLoneLetterCount + 1\n",
    "\n",
    "                        # count occurrences only for the hyperparameter being set\n",
    "                        if wordAfterHyperParameters in ham_word_count_per_email_data[\n",
    "                                dictionaryName] and count_single_instance == False:\n",
    "\n",
    "                            ham_word_count_per_email_data[dictionaryName][wordAfterHyperParameters] = ham_word_count_per_email_data[\n",
    "                                dictionaryName][wordAfterHyperParameters] + 1\n",
    "                        elif (len(wordAfterHyperParameters) > remove_words_length_threshold[1] and \n",
    "                             len(wordAfterHyperParameters) < remove_words_length_threshold[2]):\n",
    "                            ham_word_count_per_email_data[dictionaryName][wordAfterHyperParameters] = 1\n",
    "                email_counter = email_counter + 1\n",
    "                if(count_invalid_lone_letters):\n",
    "                    ham_word_count_per_email_data[dictionaryName][\"loneCnt\"] = invalidLoneLetterCount\n",
    "                if(count_upper_case_words_before_processing):\n",
    "                    ham_word_count_per_email_data[dictionaryName][\"upperCnt\"] = preProccessUpperCaseCount\n",
    "                if(count_all_symbol_words_length_threshold[0]):\n",
    "                    ham_word_count_per_email_data[dictionaryName][\"symbolCnt\"] = allSymbolWordsCount\n",
    "                if(check_markup_text_presence):\n",
    "                    if(sawMarkupWord):\n",
    "                        ham_word_count_per_email_data[dictionaryName][\"markupPrsnt\"] = 1\n",
    "                    else:\n",
    "                        ham_word_count_per_email_data[dictionaryName][\"markupPrsnt\"] = 0\n",
    "                file1.close()\n",
    "            except UnicodeDecodeError:\n",
    "                print('got unicode error with %s , trying different encoding' % en)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"DONE READING ALL EMAIL FILES\",  \"Email counts Spam: \",\n",
    "        len(spam_word_count_per_email_data), \" Ham: \",\n",
    "        len(ham_word_count_per_email_data))\n",
    "\n",
    "\n",
    "    dictionary = open(norm_dict_path, \"r\", encoding='utf-8')\n",
    "\n",
    "    all_norm_dictionary_words = []\n",
    "\n",
    "    alllines = dictionary.read()\n",
    "    alllinessplit = alllines.split()\n",
    "\n",
    "    for word in alllinessplit:\n",
    "        # upper case for the purpose of comparison later\n",
    "        all_norm_dictionary_words.append(word.upper())\n",
    "\n",
    "    dictionary.close()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    spam_dictionary = open(spam_dict_path, \"r\", encoding='utf-8')\n",
    "\n",
    "    all_spam_dictionary_words = []\n",
    "\n",
    "    alllinesspam = spam_dictionary.read()\n",
    "    alllinessplitspam = alllinesspam.split()\n",
    "\n",
    "    for word in alllinessplitspam:\n",
    "        # upper case for the purpose of comparison later\n",
    "        all_spam_dictionary_words.append(word.upper())\n",
    "\n",
    "    spam_dictionary.close()\n",
    "\n",
    "    print(\"DONE READING ALL DICTIONARY FILES\", \"Length Normal Dict: \", len(all_norm_dictionary_words),\n",
    "         \" Length Spam Dict: \", len(all_spam_dictionary_words))\n",
    "\n",
    "    return spam_word_count_per_email_data, ham_word_count_per_email_data, all_norm_dictionary_words, all_spam_dictionary_words\n",
    "\n",
    "\n",
    "spam_word_count_container, ham_word_count_container, norm_dict, spam_dict = GetDataApplyHyperparameters()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# allpossiblewords = []\n",
    "\n",
    "totalWordCount = 0\n",
    "\n",
    "for email in spam_word_count_container:\n",
    "    for word in spam_word_count_container[email]:\n",
    "        if(isMarkupWord(word) or isAllSymbolWord(word) or isPunctuation(word)):\n",
    "            print(word)\n",
    "        totalWordCount = totalWordCount + 1\n",
    "\n",
    "for email in ham_word_count_container:\n",
    "    for word in ham_word_count_container[email]:\n",
    "        if(isMarkupWord(word) or isAllSymbolWord(word) or isPunctuation(word)):\n",
    "            print(word)\n",
    "        totalWordCount = totalWordCount + 1\n",
    "\n",
    "        \n",
    "# for email in spam_word_count_container:\n",
    "#     if(spam_word_count_container[email][\"markupPrsnt\"] == 1):\n",
    "#         print(spam_word_count_container[email])\n",
    "# #         sys.exit()\n",
    "#     for word in spam_word_count_container[email]:\n",
    "#         if(allpossiblewords.count(word) == 0):\n",
    "#             # if a threshold for how long a word is to be counted is specified\n",
    "#             # check the word is valid length\n",
    "#             if(REMOVE_WORDS_LENGTH_THRESHOLD[0]):\n",
    "#                 if(len(word) > REMOVE_WORDS_LENGTH_THRESHOLD[1]):\n",
    "#                     allpossiblewords.append(word)\n",
    "#                    # print(len(allpossiblewords), \"spam addition\")\n",
    "                \n",
    "# sys.exit()\n",
    "# for email in ham_word_count_container:\n",
    "\n",
    "#     for word in ham_word_count_container[email]:\n",
    "#         if(allpossiblewords.count(word) == 0):\n",
    "#             # if a threshold for how long a word is to be counted is specified\n",
    "#             # check the word is valid length\n",
    "#             if(REMOVE_WORDS_LENGTH_THRESHOLD[0]):\n",
    "#                 if(len(word) > REMOVE_WORDS_LENGTH_THRESHOLD[1]):\n",
    "#                     allpossiblewords.append(word)\n",
    "#                     print(len(allpossiblewords), \"ham addition\")\n",
    "              \n",
    "\n",
    "\n",
    "# print(len(allpossiblewords), \"total words\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196181\n"
     ]
    }
   ],
   "source": [
    "print(totalWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19635\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#to generate random indices when picking words from an email\n",
    "def randomListOfXValuesInRange(high_lim, number_items_to_return):\n",
    "    return_vals = []\n",
    "\n",
    "    if(number_items_to_return <= 0):\n",
    "        return return_vals\n",
    "    \n",
    "    while len(return_vals) < number_items_to_return:\n",
    "        random_num = random.randrange(high_lim)\n",
    "        if(return_vals.count(random_num) == 0):\n",
    "            return_vals.append(random_num)\n",
    "    return return_vals\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def SamplePortionFromEveryEmail(container_spam, container_ham, portion_size):\n",
    "    \n",
    "    possible_words_for_sample = []\n",
    "    \n",
    "    for email in container_spam:\n",
    "        total_words_in_email = len(container_spam[email])\n",
    "        \n",
    "        random_indices = randomListOfXValuesInRange(total_words_in_email, int(round(portion_size*total_words_in_email)))\n",
    "        current_index = 0\n",
    "        for word in container_spam[email]:\n",
    "            if(random_indices.count(current_index) > 0 ):\n",
    "                possible_words_for_sample.append(word)\n",
    "            current_index = current_index + 1\n",
    "            \n",
    "    for email in container_ham:\n",
    "        total_words_in_email = len(container_ham[email])\n",
    "        \n",
    "        random_indices = randomListOfXValuesInRange(total_words_in_email, int(round(portion_size*total_words_in_email)))\n",
    "        current_index = 0\n",
    "        for word in container_ham[email]:\n",
    "            if(random_indices.count(current_index) > 0 ):\n",
    "                possible_words_for_sample.append(word)\n",
    "            current_index = current_index + 1\n",
    "    \n",
    "    return possible_words_for_sample\n",
    "\n",
    "\n",
    "words_from_sample = SamplePortionFromEveryEmail(spam_word_count_container, ham_word_count_container, 0.1)\n",
    "\n",
    "print(len(words_from_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(type(words_from_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let 1 = spam and 0 = ham\n",
    "all_train_rows = []\n",
    "\n",
    "for email in spam_word_count_container:\n",
    "    single_train_row = []\n",
    "    \n",
    "    #check if that email has the word, \n",
    "    #1 if it does, 0 if not\n",
    "    for word in words_from_sample:\n",
    "        if(word in spam_word_count_container[email]):\n",
    "            single_train_row.append(1)\n",
    "        else:\n",
    "            single_train_row.append(0)\n",
    "    #append 1 for spam for last column which is \"IsSpam\"\n",
    "    single_train_row.append(1)\n",
    "    all_train_rows.append(single_train_row)\n",
    "    \n",
    "for email in ham_word_count_container:\n",
    "    single_train_row = []\n",
    "    \n",
    "    #check if that email has the word, \n",
    "    #1 if it does, 0 if not\n",
    "    for word in words_from_sample:\n",
    "        if(word in ham_word_count_container[email]):\n",
    "            single_train_row.append(1)\n",
    "        else:\n",
    "            single_train_row.append(0)\n",
    "    #append 0 for ham for last column which is \"IsSpam\"\n",
    "    single_train_row.append(0)\n",
    "    all_train_rows.append(single_train_row)\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047\n",
      "19635\n"
     ]
    }
   ],
   "source": [
    "print(len(all_train_rows))\n",
    "print(len(words_from_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19636\n"
     ]
    }
   ],
   "source": [
    "is_spam_col = \"IsSpam\"\n",
    "words_from_sample.append(is_spam_col)\n",
    "print(len(words_from_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = pd.DataFrame(all_train_rows, columns = words_from_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2551\n",
       "1     496\n",
       "Name: IsSpam, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df[\"IsSpam\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESMTP</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>GOTHIC</th>\n",
       "      <th>SAVINGS</th>\n",
       "      <th>FAMILY</th>\n",
       "      <th>ERROR</th>\n",
       "      <th>POSTFIX</th>\n",
       "      <th>131944</th>\n",
       "      <th>MIMEOLE</th>\n",
       "      <th>LINUX</th>\n",
       "      <th>...</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>123229</th>\n",
       "      <th>080410</th>\n",
       "      <th>123231</th>\n",
       "      <th>upperCnt</th>\n",
       "      <th>GROUND</th>\n",
       "      <th>upperCnt</th>\n",
       "      <th>COURSE</th>\n",
       "      <th>symbolCnt</th>\n",
       "      <th>IsSpam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ESMTP  TABLE  GOTHIC  SAVINGS  FAMILY  ERROR  POSTFIX  131944  MIMEOLE  \\\n",
       "0      0      0       0        0       0      0        0       0        0   \n",
       "1      1      1       1        1       1      1        1       0        0   \n",
       "2      1      0       0        0       0      0        1       1        1   \n",
       "3      1      0       0        0       0      0        1       0        1   \n",
       "4      1      0       0        0       1      1        1       0        0   \n",
       "\n",
       "   LINUX  ...  METHOD  123229  080410  123231  upperCnt  GROUND  upperCnt  \\\n",
       "0      0  ...       0       0       0       0         1       0         1   \n",
       "1      0  ...       0       0       0       0         1       0         1   \n",
       "2      1  ...       0       0       0       0         1       0         1   \n",
       "3      0  ...       0       0       0       0         1       0         1   \n",
       "4      0  ...       0       0       0       0         1       0         1   \n",
       "\n",
       "   COURSE  symbolCnt  IsSpam  \n",
       "0       0          1       1  \n",
       "1       0          1       1  \n",
       "2       0          1       1  \n",
       "3       0          1       1  \n",
       "4       0          1       1  \n",
       "\n",
       "[5 rows x 19636 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train_df.drop(\"IsSpam\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Train_df[\"IsSpam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84055118, 0.96850394, 0.96059113])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "cross_val_score(forest_clf, X_train, y_train, cv=3,\n",
    "                                    scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
